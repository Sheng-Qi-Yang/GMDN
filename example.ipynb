{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9daa618c-2bf3-459b-b3d5-f4a212131a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P100-PCIE-16GB\n",
      "finish data pre-processing\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from scipy import interpolate\n",
    "import h5py\n",
    "import sys\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable \n",
    "import pickle as pk\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "#Please download the HIILines package from https://github.com/Sheng-Qi-Yang/HIILines\n",
    "from HIILines import * \n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "PoolNumber            = multiprocessing.cpu_count()\n",
    "\n",
    "#Define the MDN architecture\n",
    "class MDN(nn.Module):\n",
    "    def __init__(self, n_hidden, n_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.z_h      = nn.Sequential(nn.Linear(input_dim, n_hidden), nn.Tanh())\n",
    "        self.z_pi     = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_sigma1 = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_sigma2 = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_sigma3 = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_sigma4 = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_mu1    = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_mu2    = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_mu3    = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_mu4    = nn.Linear(n_hidden, n_gaussians)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_h    = self.z_h(x)\n",
    "        pi     = nn.functional.softmax(self.z_pi(z_h), -1)\n",
    "        sigma1 = torch.exp(self.z_sigma1(z_h))\n",
    "        sigma2 = torch.exp(self.z_sigma2(z_h))\n",
    "        sigma3 = torch.exp(self.z_sigma3(z_h))\n",
    "        sigma4 = torch.exp(self.z_sigma4(z_h))\n",
    "        mu1    = self.z_mu1(z_h)\n",
    "        mu2    = self.z_mu2(z_h)\n",
    "        mu3    = self.z_mu3(z_h)\n",
    "        mu4    = self.z_mu4(z_h)\n",
    "        return pi, sigma1, sigma2, sigma3, sigma4, mu1, mu2, mu3, mu4\n",
    "\n",
    "#Please download the SSP_Spectra_Conroy-et-al_v2.5_imfChabrier.hdf5 lookup table from https://zenodo.org/record/6338462#.ZBENinbMKbh\n",
    "fSEDTable     = h5py.File('SSP_Spectra_Conroy-et-al_v2.5_imfChabrier.hdf5','r')\n",
    "logage_Grid   = np.log10(fSEDTable['ages'][:])+3 #Myr\n",
    "logZstar_Grid = fSEDTable['metallicities'][:]    #logZ/[Z_sun]\n",
    "#Lookup table SSP_Spectra_Conroy-et-al_v2.5_imfChabrier_Q.hdf5 stores the logQ_HI for all the FSPS single star radiation spectra\n",
    "fSEDTable     = h5py.File('SSP_Spectra_Conroy-et-al_v2.5_imfChabrier_Q.hdf5','r')\n",
    "logQHITable   = fSEDTable['logQHI'][:]\n",
    "logQHIf       = interpolate.RegularGridInterpolator((logZstar_Grid,logage_Grid),logQHITable)\n",
    "MZR_FIRE      = lambda logMstar_tot: 0.38840077*logMstar_tot-3.97300904\n",
    "\n",
    "def logLMAX(X):\n",
    "    #This function computes the upper limit of LOII10, LOIII32, and LHbeta for a stellar particle with known {age, Zstar, M_{*,galaxy}}.\n",
    "    logage       = X[:,0]\n",
    "    logage[np.where(logage<logage_Grid[0])]  = logage_Grid[0]\n",
    "    logage[np.where(logage>logage_Grid[-1])] = logage_Grid[-1]\n",
    "    logZstar     = X[:,1]\n",
    "    logZstar[np.where(logZstar<logZstar_Grid[0])]  = logZstar_Grid[0]\n",
    "    logZstar[np.where(logZstar>logZstar_Grid[-1])] = logZstar_Grid[-1]\n",
    "    logMstar_tot = X[:,2]\n",
    "    pts          = np.array([[logZstar[i],logage[i]] for i in np.arange(len(logZstar))])\n",
    "    logQHI       = logQHIf(pts)\n",
    "    logZQ        = MZR_FIRE(logMstar_tot) \n",
    "\n",
    "    T4OIII       = np.zeros(len(logZQ))\n",
    "    idx          = np.where(logZQ <= -0.06)[0]\n",
    "    T4OIII[idx]  = 0.824*logZQ[idx]**2+0.101*logZQ[idx]+1.08\n",
    "    idx          = np.where(logZQ > -0.06)[0]\n",
    "    T4OIII[idx]  = 0.824*(-0.06)**2+0.101*(-0.06)+1.08\n",
    "    aTe          = -12030.22*(12+logZQ-3.31)+113720.75\n",
    "    T4OII        = aTe**2/2/T4OIII/10000/10000\n",
    "    T4OII[np.where(T4OII<0.5)] = 0.5\n",
    "\n",
    "    logLmax      = np.zeros((len(logage),3))\n",
    "    \n",
    "    logLmax[:,0] = -3.31+logZQ+np.log10(k01_OII(T4OII)*h*nu10_OII/alphaB_HI(T4OIII)*Jps2Lsun)+logQHI        #logLOII10\n",
    "    logLmax[:,1] = -3.31+logZQ+np.log10(3/4*k03_OIII(T4OIII)*h*nu32_OIII/alphaB_HI(T4OIII)*Jps2Lsun)+logQHI #logLOIII32\n",
    "    logLmax[:,2] = np.log10(h)+np.log10(nu_Hbeta*alphaB_Hbeta(T4OIII)/alphaB_HI(T4OIII)*Jps2Lsun)+logQHI    #logLHbeta\n",
    "    return logLmax\n",
    "    \n",
    "oneDivSqrtTwoPI = 1.0 / np.sqrt(2.0*np.pi) # normalization factor for Gaussians\n",
    "def gaussian_distribution(y, mu, sigma):\n",
    "    result = (y.expand_as(mu) - mu) * torch.reciprocal(sigma)\n",
    "    result = -0.5 * (result * result)\n",
    "    return torch.exp(result) * torch.reciprocal(sigma) * oneDivSqrtTwoPI\n",
    "\n",
    "def gumbel_sample(x, axis=1):\n",
    "    gs       = torch.distributions.gumbel.Gumbel(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "    z        = gs.sample(x.shape)[:,:,0].cuda()\n",
    "    w        = torch.log(x)+z\n",
    "    return w.argmax(axis=axis)\n",
    "\n",
    "input_dim             = 3\n",
    "output_dim            = 13\n",
    "scaler_X              = preprocessing.StandardScaler()\n",
    "scaler_X.mean_        = np.loadtxt('scaler_X_mean.txt')\n",
    "scaler_X.scale_       = np.loadtxt('scaler_X_scale.txt')\n",
    "scaler_Y              = preprocessing.StandardScaler()\n",
    "scaler_Y.mean_        = np.loadtxt('scaler_Y_mean.txt')\n",
    "scaler_Y.scale_       = np.loadtxt('scaler_Y_scale.txt')\n",
    "pca                   = pk.load(open('pca.pkl','rb'))\n",
    "print('finish data pre-processing')\n",
    "pca_mean_cuda         = Variable(torch.from_numpy(np.float32(pca.mean_))).cuda()\n",
    "pca_components_cuda   = Variable(torch.from_numpy(np.float32(pca.components_))).cuda()\n",
    "scalerY_mean_cuda     = Variable(torch.from_numpy(np.float32(scaler_Y.mean_))).cuda()\n",
    "scalerY_scale_cuda    = Variable(torch.from_numpy(np.float32(scaler_Y.scale_))).cuda()\n",
    "\n",
    "network               = torch.load('MDN')\n",
    "\n",
    "f            = np.loadtxt('example_stars.txt') #10 example star particles from FIRE high-z galaxy z5m12b\n",
    "logages      = f[:,0]                          #Myr\n",
    "idx          = np.where(logages<=2)[0]         #MDN is only trained to process stellar particles younger than 100 Myr\n",
    "logages      = logages[idx]\n",
    "Zstar        = 10**f[:,1][idx]                 #Z_sun\n",
    "mass         = 10**f[:,2][idx]                 #M_sun, mass of every star particles\n",
    "Mstar_tot    = 10**10.05                       #M_sun, stellar mass of the entire galaxy \n",
    "Mstar        = np.ones(len(logages))*Mstar_tot\n",
    "hist,edges   = np.histogram(logages,bins=20)\n",
    "logage_PDF   = interpolate.interp1d((edges[1:]+edges[:-1])/2,hist,bounds_error=False, fill_value=(hist[0],hist[-1]))\n",
    "weight_temp  = 1/logage_PDF(logages)\n",
    "weight       = weight_temp*len(logages)/np.sum(weight_temp)\n",
    "\n",
    "logL_MDN              = np.zeros((len(idx),13)) #Stores log(Luminosity/L_sun) for 13 lines sampled by MDN\n",
    "\n",
    "N       = len(logages)\n",
    "#X is the 3D input \n",
    "X       = np.zeros((N,input_dim))\n",
    "X[:,0]  = logages\n",
    "X[:,1]  = np.log10(Zstar)\n",
    "X[:,2]  = np.log10(Mstar)\n",
    "#Z is used for computing the LOII10 and LOIII32 upper bounds \n",
    "Z       = np.zeros((N,3))\n",
    "Z[:,0]  = logages\n",
    "Z[:,1]  = np.log10(Zstar)\n",
    "Z[:,2]  = np.log10(Mstar)\n",
    "W       = weight\n",
    "\n",
    "X_scaled         = scaler_X.transform(X)\n",
    "x_tensor         = torch.from_numpy(np.float32(X_scaled))\n",
    "x_variable       = Variable(x_tensor).cuda()\n",
    "\n",
    "idx_invalid      = np.arange(N)\n",
    "logLmax          = logLMAX(Z)\n",
    "sample2          = np.ones((N,13))*100\n",
    "\n",
    "counter          = 0\n",
    "eps              = 0\n",
    "while len(idx_invalid)>0:\n",
    "    pi, sigma1, sigma2, sigma3, sigma4, mu1, mu2, mu3, mu4 = network(x_variable[idx_invalid,:])\n",
    "    N_test             = x_variable[idx_invalid,:].shape[0]\n",
    "    k                  = gumbel_sample(pi)\n",
    "    indices            = (torch.arange(N_test), k)\n",
    "    rn                 = torch.randn(N_test).cuda()\n",
    "    sampled1           = rn * sigma1[indices] + mu1[indices]\n",
    "    sampled2           = rn * sigma2[indices] + mu2[indices]\n",
    "    sampled3           = rn * sigma3[indices] + mu3[indices]\n",
    "    sampled4           = rn * sigma4[indices] + mu4[indices]\n",
    "    sampled            = torch.zeros((N_test,4)).cuda()\n",
    "    sampled[:,0]       = sampled1\n",
    "    sampled[:,1]       = sampled2\n",
    "    sampled[:,2]       = sampled3\n",
    "    sampled[:,3]       = sampled4\n",
    "    sample_mdn1        = torch.matmul(sampled,pca_components_cuda)+pca_mean_cuda\n",
    "    sample_mdn         = sample_mdn1*scalerY_scale_cuda+scalerY_mean_cuda\n",
    "    sample2[idx_invalid,:] = sample_mdn.cpu().detach().numpy()\n",
    "    #If some random sampled results are greater than the upper bounds, abandon those results and redo the sampling.\n",
    "    idx_invalid            = np.where((sample2[:,0]-np.max(logLmax[:,0])>eps)|(sample2[:,9]-np.max(logLmax[:,1])>eps))[0]\n",
    "    counter                = counter + 1\n",
    "    if counter == 10:\n",
    "        counter = 0\n",
    "        eps     = eps + 0.1\n",
    "\n",
    "logL_MDN[:,0]  = sample2[:,0] +np.log10(mass)  #log(LOII10/L_sun)  [OII]3730A\n",
    "logL_MDN[:,1]  = sample2[:,1] +np.log10(mass)  #log(LOII20/L_sun)  [OII]3727A\n",
    "logL_MDN[:,2]  = sample2[:,2] +np.log10(mass)  #log(LOII30/L_sun)  [OII]2471.1A\n",
    "logL_MDN[:,3]  = sample2[:,3] +np.log10(mass)  #log(LOII31/L_sun)  [OII]7322A\n",
    "logL_MDN[:,4]  = sample2[:,4] +np.log10(mass)  #log(LOII32/L_sun)  [OII]7332A\n",
    "logL_MDN[:,5]  = sample2[:,5] +np.log10(mass)  #log(LOII40/L_sun)  [OII]2471.0A\n",
    "logL_MDN[:,6]  = sample2[:,6] +np.log10(mass)  #log(LOIII10/L_sun) [OIII]88 micron\n",
    "logL_MDN[:,7]  = sample2[:,7] +np.log10(mass)  #log(LOIII21/L_sun) [OIII]52 micron\n",
    "logL_MDN[:,8]  = sample2[:,8] +np.log10(mass)  #log(LOIII31/L_sun) [OIII]4960A\n",
    "logL_MDN[:,9]  = sample2[:,9] +np.log10(mass)  #log(LOIII32/L_sun) [OIII]5007A\n",
    "logL_MDN[:,10] = sample2[:,10]+np.log10(mass)  #log(LOIII43/L_sun) [OIII]4364A\n",
    "logL_MDN[:,11] = sample2[:,11]+np.log10(mass)  #log(LHalpha/L_sun) Halpha line\n",
    "logL_MDN[:,12] = sample2[:,12]+np.log10(mass)  #log(LHbeta/L_sun)  Hbeta line\n",
    "\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358dc09-48b6-48d5-b8ac-0da2b88d521e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-new-env)",
   "language": "python",
   "name": "my-new-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
